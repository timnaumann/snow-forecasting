{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The google.cloud.bigquery extension is already loaded. To reload it, use:\n",
      "  %reload_ext google.cloud.bigquery\n"
     ]
    }
   ],
   "source": [
    "%load_ext google.cloud.bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Will it snow tomorrow?\" - The time traveler asked\n",
    "The following dataset contains climate information form over 9000 stations accross the world. The overall goal of these subtasks will be to predict whether it will snow tomorrow 12 years ago. So if today is 2021.02.15 then the weather we want to forecast is for the date 2009.02.16. You are suppsed to solve the tasks using Big Query, which can be used in the Jupyter Notebook like it is shown in the following cell. For further information and how to used BigQuery in Jupyter Notebook refer to the Google Docs. \n",
    "\n",
    "The goal of this test is, to test your coding knowledge in Python, BigQuery and Pandas as well as your understanding of Data Science. If you get stuck at the first part, you can use the replacement data provided in the second part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 448.59query/s] \n",
      "Downloading: 100%|██████████| 20/20 [00:02<00:00,  8.92rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_number</th>\n",
       "      <th>wban_number</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>num_mean_temp_samples</th>\n",
       "      <th>mean_dew_point</th>\n",
       "      <th>num_mean_dew_point_samples</th>\n",
       "      <th>mean_sealevel_pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>min_temperature_explicit</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>hail</th>\n",
       "      <th>thunder</th>\n",
       "      <th>tornado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39730</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>52.799999</td>\n",
       "      <td>4</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33110</td>\n",
       "      <td>99999</td>\n",
       "      <td>1929</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37770</td>\n",
       "      <td>99999</td>\n",
       "      <td>1931</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>50.200001</td>\n",
       "      <td>4</td>\n",
       "      <td>44.299999</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>726810</td>\n",
       "      <td>24131</td>\n",
       "      <td>1931</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>65.099998</td>\n",
       "      <td>24</td>\n",
       "      <td>41.500000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>726810</td>\n",
       "      <td>24131</td>\n",
       "      <td>1931</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>42.799999</td>\n",
       "      <td>24</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>726810</td>\n",
       "      <td>24131</td>\n",
       "      <td>1931</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>726810</td>\n",
       "      <td>24131</td>\n",
       "      <td>1931</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>68.400002</td>\n",
       "      <td>24</td>\n",
       "      <td>37.200001</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>726810</td>\n",
       "      <td>24131</td>\n",
       "      <td>1932</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>64.099998</td>\n",
       "      <td>24</td>\n",
       "      <td>54.099998</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>726810</td>\n",
       "      <td>24131</td>\n",
       "      <td>1932</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>41.099998</td>\n",
       "      <td>24</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>726810</td>\n",
       "      <td>24131</td>\n",
       "      <td>1932</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>24</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>726815</td>\n",
       "      <td>24106</td>\n",
       "      <td>1932</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>726810</td>\n",
       "      <td>24131</td>\n",
       "      <td>1932</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>24</td>\n",
       "      <td>41.700001</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>726810</td>\n",
       "      <td>24131</td>\n",
       "      <td>1932</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>55.200001</td>\n",
       "      <td>24</td>\n",
       "      <td>46.599998</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>370310</td>\n",
       "      <td>99999</td>\n",
       "      <td>1933</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>55.299999</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>292310</td>\n",
       "      <td>99999</td>\n",
       "      <td>1933</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>370310</td>\n",
       "      <td>99999</td>\n",
       "      <td>1933</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>62.700001</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>239330</td>\n",
       "      <td>99999</td>\n",
       "      <td>1933</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>70.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>282750</td>\n",
       "      <td>99999</td>\n",
       "      <td>1933</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>292310</td>\n",
       "      <td>99999</td>\n",
       "      <td>1933</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>-10.300000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>370310</td>\n",
       "      <td>99999</td>\n",
       "      <td>1933</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_number  wban_number  year  month  day  mean_temp  \\\n",
       "0            39730        99999  1929     10   20  52.799999   \n",
       "1            33110        99999  1929     12   18  47.500000   \n",
       "2            37770        99999  1931      4   24  50.200001   \n",
       "3           726810        24131  1931      6   23  65.099998   \n",
       "4           726810        24131  1931      3    2  42.799999   \n",
       "5           726810        24131  1931      9   17  67.000000   \n",
       "6           726810        24131  1931      8    7  68.400002   \n",
       "7           726810        24131  1932      7   14  64.099998   \n",
       "8           726810        24131  1932     10   23  41.099998   \n",
       "9           726810        24131  1932      1    5  24.600000   \n",
       "10          726815        24106  1932      8   27  71.000000   \n",
       "11          726810        24131  1932      8   20  71.000000   \n",
       "12          726810        24131  1932      5   21  55.200001   \n",
       "13          370310        99999  1933     10   17  55.299999   \n",
       "14          292310        99999  1933     12    1 -11.000000   \n",
       "15          370310        99999  1933      6   17  62.700001   \n",
       "16          239330        99999  1933      6    4  70.500000   \n",
       "17          282750        99999  1933      1    7  -5.000000   \n",
       "18          292310        99999  1933      3   17 -10.300000   \n",
       "19          370310        99999  1933      4   23  65.000000   \n",
       "\n",
       "    num_mean_temp_samples  mean_dew_point  num_mean_dew_point_samples  \\\n",
       "0                       4       45.500000                         4.0   \n",
       "1                       4       44.000000                         4.0   \n",
       "2                       4       44.299999                         4.0   \n",
       "3                      24       41.500000                         8.0   \n",
       "4                      24       31.500000                         8.0   \n",
       "5                      24       40.500000                         8.0   \n",
       "6                      24       37.200001                         8.0   \n",
       "7                      24       54.099998                         8.0   \n",
       "8                      24       31.000000                         8.0   \n",
       "9                      24       21.100000                         8.0   \n",
       "10                     24             NaN                         NaN   \n",
       "11                     24       41.700001                         8.0   \n",
       "12                     24       46.599998                         8.0   \n",
       "13                      4             NaN                         NaN   \n",
       "14                      4             NaN                         NaN   \n",
       "15                      4             NaN                         NaN   \n",
       "16                      4             NaN                         NaN   \n",
       "17                      4             NaN                         NaN   \n",
       "18                      4             NaN                         NaN   \n",
       "19                      4             NaN                         NaN   \n",
       "\n",
       "    mean_sealevel_pressure  ...  min_temperature  min_temperature_explicit  \\\n",
       "0                      NaN  ...              NaN                      None   \n",
       "1                      NaN  ...              NaN                      None   \n",
       "2                      NaN  ...              NaN                      None   \n",
       "3                      NaN  ...              NaN                      None   \n",
       "4                      NaN  ...              NaN                      None   \n",
       "5                      NaN  ...              NaN                      None   \n",
       "6                      NaN  ...              NaN                      None   \n",
       "7                      NaN  ...              NaN                      None   \n",
       "8                      NaN  ...              NaN                      None   \n",
       "9                      NaN  ...              NaN                      None   \n",
       "10                     NaN  ...              NaN                      None   \n",
       "11                     NaN  ...              NaN                      None   \n",
       "12                     NaN  ...              NaN                      None   \n",
       "13                     NaN  ...              NaN                      None   \n",
       "14                     NaN  ...              NaN                      None   \n",
       "15                     NaN  ...              NaN                      None   \n",
       "16                     NaN  ...              NaN                      None   \n",
       "17                     NaN  ...              NaN                      None   \n",
       "18                     NaN  ...              NaN                      None   \n",
       "19                     NaN  ...              NaN                      None   \n",
       "\n",
       "    total_precipitation  snow_depth    fog   rain   snow   hail  thunder  \\\n",
       "0                   0.0         NaN  False  False  False  False    False   \n",
       "1                   NaN         NaN  False  False  False  False    False   \n",
       "2                   NaN         NaN  False  False  False  False    False   \n",
       "3                   0.0         NaN  False  False  False  False    False   \n",
       "4                   0.0         NaN  False  False  False  False    False   \n",
       "5                   0.0         NaN  False  False  False  False    False   \n",
       "6                   0.0         NaN  False  False  False  False    False   \n",
       "7                   NaN         NaN  False  False  False  False    False   \n",
       "8                   NaN         NaN  False  False  False  False    False   \n",
       "9                   NaN         NaN   True   True   True   True     True   \n",
       "10                  0.0         NaN  False  False  False  False    False   \n",
       "11                  0.0         NaN  False  False  False  False    False   \n",
       "12                  NaN         NaN  False  False  False  False    False   \n",
       "13                  0.0         NaN  False  False  False  False    False   \n",
       "14                  NaN         NaN  False  False  False  False    False   \n",
       "15                  0.0         NaN  False  False  False  False    False   \n",
       "16                  0.0         NaN   True   True   True   True     True   \n",
       "17                  0.0         NaN  False  False  False  False    False   \n",
       "18                  0.0         NaN  False  False  False  False    False   \n",
       "19                  0.0         NaN  False  False  False  False    False   \n",
       "\n",
       "    tornado  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  \n",
       "5     False  \n",
       "6     False  \n",
       "7     False  \n",
       "8     False  \n",
       "9      True  \n",
       "10    False  \n",
       "11    False  \n",
       "12    False  \n",
       "13    False  \n",
       "14    False  \n",
       "15    False  \n",
       "16     True  \n",
       "17    False  \n",
       "18    False  \n",
       "19    False  \n",
       "\n",
       "[20 rows x 31 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery \n",
    "SELECT\n",
    "*,\n",
    "FROM `bigquery-public-data.samples.gsod`\n",
    "LIMIT 20 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Task\n",
    "Change the date format to 'YYYY-MM-DD' and select the data from 2005 till 2009 for station numbers including and between 725300 and 726300 , and save it as a pandas dataframe. Note the maximum year available is 2010. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION, in order to predict snow 12 years ago we need data for 2010 as well, so I just move the time-series window\n",
    "# to 2005 - 2010\n",
    "from google.cloud import bigquery\n",
    "\n",
    "bqclient = bigquery.Client()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT CAST(CONCAT(year,\"-\",month,\"-\",day) AS DATE) AS date, * \n",
    "FROM `bigquery-public-data.samples.gsod` \n",
    "WHERE year BETWEEN 2006 AND 2010\n",
    "    AND station_number BETWEEN 725300 AND 726300\n",
    "\"\"\"\n",
    "\n",
    "data = (bqclient.query(query).result().to_dataframe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'station_number', 'wban_number', 'year', 'month', 'day',\n",
       "       'mean_temp', 'num_mean_temp_samples', 'mean_dew_point',\n",
       "       'num_mean_dew_point_samples', 'mean_sealevel_pressure',\n",
       "       'num_mean_sealevel_pressure_samples', 'mean_station_pressure',\n",
       "       'num_mean_station_pressure_samples', 'mean_visibility',\n",
       "       'num_mean_visibility_samples', 'mean_wind_speed',\n",
       "       'num_mean_wind_speed_samples', 'max_sustained_wind_speed',\n",
       "       'max_gust_wind_speed', 'max_temperature', 'max_temperature_explicit',\n",
       "       'min_temperature', 'min_temperature_explicit', 'total_precipitation',\n",
       "       'snow_depth', 'fog', 'rain', 'snow', 'hail', 'thunder', 'tornado'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>min_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.800003</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.799999</td>\n",
       "      <td>47.799999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.400000</td>\n",
       "      <td>19.799999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.200001</td>\n",
       "      <td>35.599998</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>18.299999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323796</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>45.700001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323797</th>\n",
       "      <td>-0.400000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323798</th>\n",
       "      <td>19.400000</td>\n",
       "      <td>29.200001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323799</th>\n",
       "      <td>21.200001</td>\n",
       "      <td>26.799999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323800</th>\n",
       "      <td>24.799999</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323801 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        max_temperature  mean_temp  min_temperature\n",
       "0             69.800003  86.000000              NaN\n",
       "1             42.799999  47.799999              NaN\n",
       "2             19.400000  19.799999              NaN\n",
       "3             30.200001  35.599998              NaN\n",
       "4             12.000000  18.299999              NaN\n",
       "...                 ...        ...              ...\n",
       "323796        25.000000  45.700001              NaN\n",
       "323797        -0.400000   6.000000              NaN\n",
       "323798        19.400000  29.200001              NaN\n",
       "323799        21.200001  26.799999              NaN\n",
       "323800        24.799999  32.500000              NaN\n",
       "\n",
       "[323801 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['max_temperature', 'mean_temp', 'min_temperature']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Task \n",
    "From here want to work with the data from all stations 725300 to 725330 that have information from 2005 till 2009. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>station_number</th>\n",
       "      <th>wban_number</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>num_mean_temp_samples</th>\n",
       "      <th>mean_dew_point</th>\n",
       "      <th>num_mean_dew_point_samples</th>\n",
       "      <th>...</th>\n",
       "      <th>min_temperature</th>\n",
       "      <th>min_temperature_explicit</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>snow_depth</th>\n",
       "      <th>fog</th>\n",
       "      <th>rain</th>\n",
       "      <th>snow</th>\n",
       "      <th>hail</th>\n",
       "      <th>thunder</th>\n",
       "      <th>tornado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-06-25</td>\n",
       "      <td>725835</td>\n",
       "      <td>99999</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>34.700001</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-10-16</td>\n",
       "      <td>725835</td>\n",
       "      <td>99999</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>47.799999</td>\n",
       "      <td>4</td>\n",
       "      <td>41.900002</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-12-04</td>\n",
       "      <td>725409</td>\n",
       "      <td>99999</td>\n",
       "      <td>2006</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>19.799999</td>\n",
       "      <td>5</td>\n",
       "      <td>16.200001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-18</td>\n",
       "      <td>725869</td>\n",
       "      <td>99999</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>35.599998</td>\n",
       "      <td>5</td>\n",
       "      <td>31.299999</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-06</td>\n",
       "      <td>725868</td>\n",
       "      <td>99999</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>18.299999</td>\n",
       "      <td>5</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  station_number  wban_number  year  month  day  mean_temp  \\\n",
       "0 2006-06-25          725835        99999  2006      6   25  86.000000   \n",
       "1 2006-10-16          725835        99999  2006     10   16  47.799999   \n",
       "2 2006-12-04          725409        99999  2006     12    4  19.799999   \n",
       "3 2006-01-18          725869        99999  2006      1   18  35.599998   \n",
       "4 2006-01-06          725868        99999  2006      1    6  18.299999   \n",
       "\n",
       "   num_mean_temp_samples  mean_dew_point  num_mean_dew_point_samples  ...  \\\n",
       "0                      4       34.700001                         4.0  ...   \n",
       "1                      4       41.900002                         4.0  ...   \n",
       "2                      5       16.200001                         5.0  ...   \n",
       "3                      5       31.299999                         5.0  ...   \n",
       "4                      5       16.500000                         5.0  ...   \n",
       "\n",
       "   min_temperature  min_temperature_explicit  total_precipitation  snow_depth  \\\n",
       "0              NaN                      None                 0.00         NaN   \n",
       "1              NaN                      None                 0.15         NaN   \n",
       "2              NaN                      None                  NaN         NaN   \n",
       "3              NaN                      None                 0.29         NaN   \n",
       "4              NaN                      None                 0.00         2.0   \n",
       "\n",
       "     fog   rain   snow   hail  thunder  tornado  \n",
       "0  False  False  False  False    False    False  \n",
       "1  False  False  False  False    False    False  \n",
       "2  False  False  False  False    False    False  \n",
       "3  False  False  False  False    False    False  \n",
       "4  False  False  False  False    False    False  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_by_station_number = data[data['station_number'].between(725300,725330)]\n",
    "filtered_data_by_station_number.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'station_number', 'wban_number', 'year', 'month', 'day',\n",
       "       'mean_temp', 'num_mean_temp_samples', 'mean_dew_point',\n",
       "       'num_mean_dew_point_samples', 'mean_sealevel_pressure',\n",
       "       'num_mean_sealevel_pressure_samples', 'mean_station_pressure',\n",
       "       'num_mean_station_pressure_samples', 'mean_visibility',\n",
       "       'num_mean_visibility_samples', 'mean_wind_speed',\n",
       "       'num_mean_wind_speed_samples', 'max_sustained_wind_speed',\n",
       "       'max_gust_wind_speed', 'max_temperature', 'max_temperature_explicit',\n",
       "       'min_temperature', 'min_temperature_explicit', 'total_precipitation',\n",
       "       'snow_depth', 'fog', 'rain', 'snow', 'hail', 'thunder', 'tornado'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data_by_station_number.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a first analysis of the remaining dataset, clean or drop data depending on how you see appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after a first look at the available data it seems that a lot of fields are present (*._samples) that do not have any \n",
    "# valuable information for our use-case (based on the assumption that the fields are correctly labeled)\n",
    "# same applies to year, month, day and the wban_number which do not have any value for us as well\n",
    "# this results in a manual feature selection in the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_mean_temp_samples</th>\n",
       "      <th>num_mean_dew_point_samples</th>\n",
       "      <th>num_mean_sealevel_pressure_samples</th>\n",
       "      <th>num_mean_station_pressure_samples</th>\n",
       "      <th>num_mean_visibility_samples</th>\n",
       "      <th>num_mean_wind_speed_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15557</th>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15558</th>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15559</th>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15560</th>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15561</th>\n",
       "      <td>24</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15562 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_mean_temp_samples  num_mean_dew_point_samples  \\\n",
       "0                         15                        15.0   \n",
       "1                         24                        24.0   \n",
       "2                         24                        24.0   \n",
       "3                         24                        24.0   \n",
       "4                         24                        24.0   \n",
       "...                      ...                         ...   \n",
       "15557                     24                        24.0   \n",
       "15558                     24                        24.0   \n",
       "15559                     24                        24.0   \n",
       "15560                     24                        24.0   \n",
       "15561                     24                        24.0   \n",
       "\n",
       "       num_mean_sealevel_pressure_samples  num_mean_station_pressure_samples  \\\n",
       "0                                     NaN                                NaN   \n",
       "1                                     NaN                                NaN   \n",
       "2                                     NaN                                NaN   \n",
       "3                                     NaN                                NaN   \n",
       "4                                     NaN                                NaN   \n",
       "...                                   ...                                ...   \n",
       "15557                                24.0                                NaN   \n",
       "15558                                24.0                                NaN   \n",
       "15559                                24.0                                NaN   \n",
       "15560                                24.0                                NaN   \n",
       "15561                                24.0                                NaN   \n",
       "\n",
       "       num_mean_visibility_samples  num_mean_wind_speed_samples  \n",
       "0                             15.0                         15.0  \n",
       "1                             24.0                         24.0  \n",
       "2                             24.0                         24.0  \n",
       "3                             24.0                         24.0  \n",
       "4                             24.0                         24.0  \n",
       "...                            ...                          ...  \n",
       "15557                         24.0                         24.0  \n",
       "15558                         24.0                         24.0  \n",
       "15559                         24.0                         24.0  \n",
       "15560                         24.0                         24.0  \n",
       "15561                         24.0                         24.0  \n",
       "\n",
       "[15562 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = filtered_data_by_station_number.filter(regex=(\".*_samples\"))\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_sample_columns(data):\n",
    "    filtered_data = data.drop(columns=['num_mean_temp_samples', 'num_mean_dew_point_samples', 'num_mean_sealevel_pressure_samples',\n",
    "                             'num_mean_station_pressure_samples', 'num_mean_visibility_samples', 'num_mean_wind_speed_samples'])\n",
    "    return filtered_data\n",
    "\n",
    "def delete_date_columns(data):\n",
    "    filtered_data = data.drop(columns=['year', 'month', 'day'])\n",
    "    return filtered_data\n",
    "\n",
    "def delete_wban_column(data):\n",
    "    filtered_data = data.drop(columns=['wban_number'])\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and recognized that max_temperature_explicit, min_temperature_explicit and min_temperature use boolean as type (max_temperature_explicit)\n",
    "# or have \"none\" or NaN values only (min_temperature_explicit, min_temperature), no real information gain as well\n",
    "def delete_temperature_explicit_columns(data):\n",
    "    filtered_data = data.drop(columns=['max_temperature_explicit', 'min_temperature_explicit', 'min_temperature'])\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_by_station_number = delete_sample_columns(filtered_data_by_station_number)\n",
    "filtered_data_by_station_number = delete_date_columns(filtered_data_by_station_number)\n",
    "filtered_data_by_station_number = delete_wban_column(filtered_data_by_station_number)\n",
    "filtered_data_by_station_number = delete_temperature_explicit_columns(filtered_data_by_station_number)\n",
    "\n",
    "# Note: on an intuitive level, snow_depth also makes no sense to keep it, however, lets check\n",
    "# correlation first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('station_number', False, 0),\n",
       " ('mean_temp', False, 0),\n",
       " ('mean_dew_point', True, 2),\n",
       " ('mean_sealevel_pressure', True, 1569),\n",
       " ('mean_station_pressure', True, 15276),\n",
       " ('mean_visibility', True, 3),\n",
       " ('mean_wind_speed', True, 5),\n",
       " ('max_sustained_wind_speed', True, 9),\n",
       " ('max_gust_wind_speed', True, 5557),\n",
       " ('total_precipitation', True, 152),\n",
       " ('snow_depth', True, 15059),\n",
       " ('fog', False, 0),\n",
       " ('rain', False, 0),\n",
       " ('hail', False, 0),\n",
       " ('thunder', False, 0),\n",
       " ('tornado', False, 0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now check for nan values:\n",
    "feature_columns = [x for x in filtered_data_by_station_number.columns.tolist() if x != \"snow\" and x != \"date\"]\n",
    "\n",
    "def check_if_column_has_nan_values(data, column):\n",
    "    return (column, filtered_data_by_station_number[column].isnull().values.any(), filtered_data_by_station_number[column].isnull().sum())\n",
    "\n",
    "nan_values = [check_if_column_has_nan_values(filtered_data_by_station_number, x) for x in feature_columns]\n",
    "nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it can be seen that a lot of data is missing some values (snow_depth, mean_station_pressure, max_gust_wind_speed)\n",
    "# lets check the correlation to get more insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_number             -0.009668\n",
       "mean_temp                  -0.088404\n",
       "mean_dew_point             -0.018742\n",
       "mean_sealevel_pressure     -0.068699\n",
       "mean_station_pressure      -0.060517\n",
       "mean_visibility            -0.466942\n",
       "mean_wind_speed            -0.001578\n",
       "max_sustained_wind_speed    0.041220\n",
       "max_gust_wind_speed         0.112406\n",
       "total_precipitation         0.100985\n",
       "snow_depth                  0.136975\n",
       "fog                         1.000000\n",
       "rain                        1.000000\n",
       "snow                        1.000000\n",
       "hail                        1.000000\n",
       "thunder                     1.000000\n",
       "tornado                     1.000000\n",
       "Name: snow, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation_matrix = filtered_data_by_station_number.corr()\n",
    "correlation_matrix['snow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it seems that columns representing weather phenomena are identical with snow, the following problems evolve:\n",
    "# first, combinations of these phenomena does not really make sense (I assume that rain is not present while snowing)\n",
    "# second, our model would learn that these features are 100% correct indicators while predicting snow which \n",
    "# would distort our test results, therefore, I decided to delete them\n",
    "def delete_weather_target_columns(data):\n",
    "    filtered_data = data.drop(columns=['thunder', 'tornado', 'hail', 'rain', 'fog'])\n",
    "    return filtered_data\n",
    "\n",
    "filtered_data_by_station_number = delete_weather_target_columns(filtered_data_by_station_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to the sheer amount of missing data and correlation, I decided to remove features snow_depth, max_gust_wind_speed \n",
    "# mean_station_pressure\n",
    "def delete_dedicated_feature_columns(data):\n",
    "    filtered_data = data.drop(columns=['snow_depth', 'max_gust_wind_speed', 'mean_station_pressure'])\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_by_station_number = delete_dedicated_feature_columns(filtered_data_by_station_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/7learningsFirst/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('station_number', False, 0),\n",
       " ('mean_temp', False, 0),\n",
       " ('mean_dew_point', False, 0),\n",
       " ('mean_sealevel_pressure', False, 0),\n",
       " ('mean_visibility', False, 0),\n",
       " ('mean_wind_speed', False, 0),\n",
       " ('max_sustained_wind_speed', False, 0),\n",
       " ('total_precipitation', False, 0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill up the rest with the mean\n",
    "filtered_data_by_station_number = filtered_data_by_station_number.fillna(filtered_data_by_station_number.mean())\n",
    "\n",
    "numeric_feature_columns = [x for x in filtered_data_by_station_number.columns.tolist() if x != \"snow\" and x != \"date\"]\n",
    "nan_values = [check_if_column_has_nan_values(filtered_data_by_station_number, x) for x in numeric_feature_columns]\n",
    "nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is clean, lets split it up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Task\n",
    "Now it is time to split the data, into a training, evaluation and test set. As a reminder, the date we are trying to predict snow fall for is the following, and hence should constitute your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-02-04'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime, timedelta\n",
    "\n",
    "day_to_predict = str(datetime.datetime.today()- datetime.timedelta(days=12*365)).split(' ')[0]\n",
    "day_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming just for readability purposes\n",
    "features_df = filtered_data_by_station_number\n",
    "features_df[\"snow\"] = filtered_data_by_station_number[\"snow\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_station(complete_data, station_number):\n",
    "    return complete_data[complete_data['station_number'] == station_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='date'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check how snow is distributed over the data-set\n",
    "# maybe we can already see an appropriate split\n",
    "# snow is not uniformly distributed (as expected), however, stations seem to be really all over the world \n",
    "# due to a baseline of snow over the year\n",
    "features_df[['date','snow']].set_index('date').resample('m').sum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readd year + month + day of year to allow to filtering later on, day of year may be a good indicator as well\n",
    "features_df['year'] = pd.DatetimeIndex(features_df['date']).year\n",
    "features_df['month'] = pd.DatetimeIndex(features_df['date']).month\n",
    "features_df['day_of_year'] = pd.DatetimeIndex(features_df['date']).day_of_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## one hot encoder for stations\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_station_encoder = OneHotEncoder()\n",
    "one_hot_station_encoder.fit(filtered_data_by_station_number['station_number'].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_number_to_one_hot_vec(df):\n",
    "    station_numbers_vec = df['station_number'].to_numpy().reshape(-1, 1)\n",
    "    return one_hot_station_encoder.transform(station_numbers_vec).toarray()\n",
    "\n",
    "def remove_non_feature_columns(df):\n",
    "    return df.drop(columns=['year', 'date', 'station_number', 'snow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit standardscaler for later\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(remove_non_feature_columns(features_df).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# fist, split the data at random to quickly check linear classifier (as baseline)\n",
    "def split_data_randomly(df):\n",
    "    targets = df['snow'].to_numpy()\n",
    "    feature_df = remove_non_feature_columns(df)\n",
    "    \n",
    "    station_vec = station_number_to_one_hot_vec(df)\n",
    "    feature_matrix = np.hstack((scaler.transform(feature_df.to_numpy()), station_vec))\n",
    "    \n",
    "    return train_test_split(feature_matrix, targets, test_size=0.15)\n",
    "random_training_data, random_val_data, random_training_targets, random_val_targets = split_data_randomly(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_feature_matrix(df):\n",
    "    station_numbers_vec = df['station_number'].to_numpy().reshape(-1, 1)\n",
    "    \n",
    "    feature_df = remove_non_feature_columns(df)\n",
    "\n",
    "    ## to numpy and normalize\n",
    "    feature_matrix = scaler.transform(feature_df.to_numpy())\n",
    "    \n",
    "    # encode stations to one-hot and add \n",
    "    encoded_station_number = station_number_to_one_hot_vec(df)\n",
    "    return np.hstack((feature_matrix, encoded_station_number))\n",
    "    \n",
    "\n",
    "# for each month of each year, group the data by station and do the following\n",
    "# take time_stamps_amount of rows as window for data of each station, the row after the time_stamps_amount'th\n",
    "# row represents the target\n",
    "# the stride determines how to shift the window over the station data\n",
    "# val_sample determines which sample should be part of the validation set\n",
    "# to allow prediction of snow 12 years ago, use the complete year 2010 as test-data with stride = 1\n",
    "def split_data_in_time_series(data, time_stamps_amount, train_stride, val_sample):\n",
    "    train_samples = []\n",
    "    train_targets = []\n",
    "    \n",
    "    val_samples = []\n",
    "    val_targets = []\n",
    "    \n",
    "    test_samples = []\n",
    "    test_targets = []\n",
    "    \n",
    "    month_year_groups = data.groupby(['month','year']).size().reset_index().rename(columns={0:'count'}).sort_values(by=\"year\")\n",
    "    \n",
    "    for index, row in month_year_groups.iterrows():\n",
    "        year = row['year']\n",
    "        month = row['month']\n",
    "        \n",
    "        month_data = data[(data['year'] == year) & (data['month'] == month)]\n",
    "        \n",
    "        stations = month_data['station_number'].unique()\n",
    "        \n",
    "        for station in stations:\n",
    "            \n",
    "            station_data = month_data[month_data['station_number'] == station].sort_values(by=\"date\")\n",
    "            \n",
    "            total_amount_of_timestamps = station_data.shape[0]\n",
    "            \n",
    "            iteration_counter = 0\n",
    "            row_counter = 0\n",
    "            \n",
    "            while (row_counter + time_stamps_amount + 1) <= total_amount_of_timestamps:\n",
    "                time_stamps_range = np.arange(row_counter, row_counter + time_stamps_amount, 1)\n",
    "                \n",
    "                feature_matrix = df_to_feature_matrix(station_data.iloc[time_stamps_range])\n",
    "                target = (station_data.iloc[row_counter + time_stamps_amount])['snow']\n",
    "                \n",
    "                if year == 2010:\n",
    "                    test_samples.append(feature_matrix)\n",
    "                    test_targets.append(target)\n",
    "                    \n",
    "                    # stride = 1\n",
    "                    row_counter = row_counter + 1\n",
    "                elif ((iteration_counter + 1) % val_sample) == 0:\n",
    "                    val_samples.append(feature_matrix)\n",
    "                    val_targets.append(target)\n",
    "                    \n",
    "                    # stride = time_stamps_amount, train and val set should not overlap\n",
    "                    row_counter = row_counter + time_stamps_amount\n",
    "                else:\n",
    "                    train_samples.append(feature_matrix)\n",
    "                    train_targets.append(target)\n",
    "                    \n",
    "                    # stride = train_stride\n",
    "                    row_counter = row_counter + train_stride\n",
    "                    \n",
    "                iteration_counter = iteration_counter + 1\n",
    "    \n",
    "    return np.stack(train_samples), np.stack(train_targets), np.stack(val_samples), np.stack(val_targets), np.stack(test_samples), np.stack(test_targets) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8501, 4, 19)\n",
      "(8501,)\n",
      "(1209, 4, 19)\n",
      "(1209,)\n",
      "(900, 4, 19)\n",
      "(900,)\n"
     ]
    }
   ],
   "source": [
    "time_stamp_amount = 4\n",
    "stride = 1\n",
    "val_sample = 7\n",
    "\n",
    "time_series_training_data, time_series_training_targets, time_series_val_data, time_series_val_targets, time_series_test_data, time_series_test_targets  = split_data_in_time_series(features_df, time_stamp_amount, stride, val_sample)\n",
    "\n",
    "print(time_series_training_data.shape)\n",
    "print(time_series_training_targets.shape)\n",
    "print(time_series_val_data.shape)\n",
    "print(time_series_val_targets.shape)\n",
    "print(time_series_test_data.shape)\n",
    "print(time_series_test_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "If you made it up to here all by yourself, you can use your prepared dataset to train an Algorithm of your choice to forecast whether it will snow on the following date for each station in this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-02-04'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime, timedelta\n",
    "\n",
    "day_to_predict = str(datetime.datetime.today()- datetime.timedelta(days=12*365)).split(' ')[0]\n",
    "day_to_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are allowed to use any library you are comfortable with such as sklearn, tensorflow keras etc. \n",
    "If you did not manage to finish part one feel free to use the data provided in 'coding_challenge.csv' Note that this data does not represent a solution to Part 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_range = np.arange(0.2, 6, 0.2, dtype=float)\n",
    "def plot_validation_curve_for_svm_reg_param(c_range):\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for c in c_range:\n",
    "        model = svm.SVC(C=c)\n",
    "        model.fit(random_training_data, random_training_targets)\n",
    "\n",
    "        val_predicts = model.predict(random_val_data)\n",
    "        \n",
    "        support = precision_recall_fscore_support(random_val_targets, val_predicts, average=\"binary\")\n",
    "        precision = support[0]\n",
    "        recall = support[1]\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        accuracies.append(accuracy_score(random_val_targets, val_predicts))\n",
    "       \n",
    "    plt.plot(c_range, precisions, 'r', label=\"precision\")\n",
    "    plt.plot(c_range, recalls, 'b', label=\"recall\")\n",
    "    plt.plot(c_range, accuracies, 'g', label=\"accuracy\") \n",
    "    plt.xlabel(\"Regularization Param\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()\n",
    "    \n",
    "plot_validation_curve_for_svm_reg_param(c_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data to not have station data in batches\n",
    "from sklearn.utils import shuffle\n",
    "time_series_training_data_shuffled, time_series_training_targets_shuffled = shuffle(time_series_training_data, time_series_training_targets, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a lstm model\n",
    "def define_lstm_model(feature_matrix):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_shape=(feature_matrix[0].shape[0], feature_matrix[0].shape[1])))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = define_lstm_model(time_series_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10)                1200      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                110       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,321\n",
      "Trainable params: 1,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "133/133 [==============================] - 2s 6ms/step - loss: 0.4726 - precision: 0.0936 - recall: 0.0438 - val_loss: 0.3739 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2899 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3522 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2729 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3411 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2672 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3344 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2635 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3317 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2606 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3297 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2578 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3239 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2555 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3229 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2537 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.3195 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2519 - precision: 1.0000 - recall: 0.0014 - val_loss: 0.3196 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2501 - precision: 0.8000 - recall: 0.0055 - val_loss: 0.3195 - val_precision: 1.0000 - val_recall: 0.0143\n",
      "Epoch 12/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2482 - precision: 0.7143 - recall: 0.0137 - val_loss: 0.3138 - val_precision: 1.0000 - val_recall: 0.0286\n",
      "Epoch 13/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2463 - precision: 0.6842 - recall: 0.0178 - val_loss: 0.3215 - val_precision: 1.0000 - val_recall: 0.0357\n",
      "Epoch 14/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2449 - precision: 0.6522 - recall: 0.0205 - val_loss: 0.3186 - val_precision: 0.8182 - val_recall: 0.0643\n",
      "Epoch 15/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2437 - precision: 0.6111 - recall: 0.0301 - val_loss: 0.3163 - val_precision: 0.8000 - val_recall: 0.0571\n",
      "Epoch 16/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2420 - precision: 0.7027 - recall: 0.0356 - val_loss: 0.3238 - val_precision: 0.8571 - val_recall: 0.0857\n",
      "Epoch 17/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2406 - precision: 0.7561 - recall: 0.0424 - val_loss: 0.3230 - val_precision: 0.8824 - val_recall: 0.1071\n",
      "Epoch 18/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2393 - precision: 0.6765 - recall: 0.0629 - val_loss: 0.3233 - val_precision: 0.9091 - val_recall: 0.0714\n",
      "Epoch 19/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2381 - precision: 0.7213 - recall: 0.0602 - val_loss: 0.3205 - val_precision: 0.8400 - val_recall: 0.1500\n",
      "Epoch 20/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2368 - precision: 0.7361 - recall: 0.0725 - val_loss: 0.3197 - val_precision: 0.7778 - val_recall: 0.1500\n",
      "Epoch 21/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2355 - precision: 0.6914 - recall: 0.0766 - val_loss: 0.3274 - val_precision: 0.7692 - val_recall: 0.1429\n",
      "Epoch 22/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2351 - precision: 0.6790 - recall: 0.0752 - val_loss: 0.3268 - val_precision: 0.7407 - val_recall: 0.1429\n",
      "Epoch 23/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2336 - precision: 0.6869 - recall: 0.0930 - val_loss: 0.3218 - val_precision: 0.6667 - val_recall: 0.1571\n",
      "Epoch 24/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2326 - precision: 0.6875 - recall: 0.1053 - val_loss: 0.3233 - val_precision: 0.6774 - val_recall: 0.1500\n",
      "Epoch 25/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2319 - precision: 0.6639 - recall: 0.1108 - val_loss: 0.3219 - val_precision: 0.6562 - val_recall: 0.1500\n",
      "Epoch 26/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2314 - precision: 0.6693 - recall: 0.1163 - val_loss: 0.3217 - val_precision: 0.6176 - val_recall: 0.1500\n",
      "Epoch 27/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2293 - precision: 0.6818 - recall: 0.1231 - val_loss: 0.3342 - val_precision: 0.6047 - val_recall: 0.1857\n",
      "Epoch 28/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2285 - precision: 0.6690 - recall: 0.1300 - val_loss: 0.3271 - val_precision: 0.6111 - val_recall: 0.1571\n",
      "Epoch 29/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2283 - precision: 0.6906 - recall: 0.1313 - val_loss: 0.3202 - val_precision: 0.6364 - val_recall: 0.1500\n",
      "Epoch 30/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2277 - precision: 0.6831 - recall: 0.1327 - val_loss: 0.3318 - val_precision: 0.6562 - val_recall: 0.1500\n",
      "Epoch 31/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2267 - precision: 0.6741 - recall: 0.1245 - val_loss: 0.3231 - val_precision: 0.5814 - val_recall: 0.1786\n",
      "Epoch 32/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2258 - precision: 0.6405 - recall: 0.1341 - val_loss: 0.3250 - val_precision: 0.6176 - val_recall: 0.1500\n",
      "Epoch 33/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2255 - precision: 0.7070 - recall: 0.1518 - val_loss: 0.3261 - val_precision: 0.6216 - val_recall: 0.1643\n",
      "Epoch 34/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2249 - precision: 0.6627 - recall: 0.1532 - val_loss: 0.3253 - val_precision: 0.6286 - val_recall: 0.1571\n",
      "Epoch 35/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2239 - precision: 0.7006 - recall: 0.1505 - val_loss: 0.3260 - val_precision: 0.5714 - val_recall: 0.1714\n",
      "Epoch 36/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2234 - precision: 0.6946 - recall: 0.1587 - val_loss: 0.3305 - val_precision: 0.6053 - val_recall: 0.1643\n",
      "Epoch 37/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2223 - precision: 0.6975 - recall: 0.1546 - val_loss: 0.3259 - val_precision: 0.6389 - val_recall: 0.1643\n",
      "Epoch 38/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2215 - precision: 0.6686 - recall: 0.1601 - val_loss: 0.3266 - val_precision: 0.6774 - val_recall: 0.1500\n",
      "Epoch 39/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2209 - precision: 0.6919 - recall: 0.1628 - val_loss: 0.3200 - val_precision: 0.5610 - val_recall: 0.1643\n",
      "Epoch 40/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2205 - precision: 0.7062 - recall: 0.1710 - val_loss: 0.3256 - val_precision: 0.5897 - val_recall: 0.1643\n",
      "Epoch 41/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2196 - precision: 0.6897 - recall: 0.1642 - val_loss: 0.3241 - val_precision: 0.6053 - val_recall: 0.1643\n",
      "Epoch 42/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2187 - precision: 0.6593 - recall: 0.1642 - val_loss: 0.3359 - val_precision: 0.6000 - val_recall: 0.1714\n",
      "Epoch 43/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2188 - precision: 0.7069 - recall: 0.1683 - val_loss: 0.3255 - val_precision: 0.5750 - val_recall: 0.1643\n",
      "Epoch 44/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2174 - precision: 0.6931 - recall: 0.1792 - val_loss: 0.3322 - val_precision: 0.5227 - val_recall: 0.1643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2168 - precision: 0.7047 - recall: 0.1860 - val_loss: 0.3344 - val_precision: 0.4727 - val_recall: 0.1857\n",
      "Epoch 46/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2162 - precision: 0.6802 - recall: 0.1833 - val_loss: 0.3284 - val_precision: 0.5333 - val_recall: 0.1714\n",
      "Epoch 47/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2159 - precision: 0.6881 - recall: 0.1902 - val_loss: 0.3318 - val_precision: 0.5476 - val_recall: 0.1643\n",
      "Epoch 48/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2146 - precision: 0.7287 - recall: 0.1874 - val_loss: 0.3354 - val_precision: 0.5476 - val_recall: 0.1643\n",
      "Epoch 49/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2149 - precision: 0.6981 - recall: 0.2025 - val_loss: 0.3316 - val_precision: 0.5116 - val_recall: 0.1571\n",
      "Epoch 50/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2134 - precision: 0.6942 - recall: 0.1956 - val_loss: 0.3372 - val_precision: 0.5217 - val_recall: 0.1714\n",
      "Epoch 51/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2134 - precision: 0.7009 - recall: 0.2052 - val_loss: 0.3363 - val_precision: 0.5676 - val_recall: 0.1500\n",
      "Epoch 52/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2122 - precision: 0.6759 - recall: 0.1997 - val_loss: 0.3305 - val_precision: 0.5385 - val_recall: 0.1500\n",
      "Epoch 53/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2120 - precision: 0.6901 - recall: 0.2011 - val_loss: 0.3405 - val_precision: 0.5366 - val_recall: 0.1571\n",
      "Epoch 54/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2112 - precision: 0.7171 - recall: 0.2011 - val_loss: 0.3302 - val_precision: 0.5000 - val_recall: 0.1643\n",
      "Epoch 55/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2107 - precision: 0.7087 - recall: 0.1997 - val_loss: 0.3391 - val_precision: 0.5217 - val_recall: 0.1714\n",
      "Epoch 56/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2099 - precision: 0.6964 - recall: 0.2134 - val_loss: 0.3355 - val_precision: 0.5526 - val_recall: 0.1500\n",
      "Epoch 57/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2098 - precision: 0.7277 - recall: 0.2120 - val_loss: 0.3431 - val_precision: 0.5111 - val_recall: 0.1643\n",
      "Epoch 58/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2097 - precision: 0.7040 - recall: 0.2148 - val_loss: 0.3329 - val_precision: 0.4898 - val_recall: 0.1714\n",
      "Epoch 59/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2082 - precision: 0.6897 - recall: 0.2189 - val_loss: 0.3337 - val_precision: 0.5208 - val_recall: 0.1786\n",
      "Epoch 60/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2079 - precision: 0.7217 - recall: 0.2271 - val_loss: 0.3315 - val_precision: 0.5476 - val_recall: 0.1643\n",
      "Epoch 61/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2073 - precision: 0.6992 - recall: 0.2257 - val_loss: 0.3330 - val_precision: 0.5094 - val_recall: 0.1929\n",
      "Epoch 62/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2074 - precision: 0.7285 - recall: 0.2202 - val_loss: 0.3366 - val_precision: 0.5000 - val_recall: 0.1929\n",
      "Epoch 63/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2061 - precision: 0.7273 - recall: 0.2298 - val_loss: 0.3298 - val_precision: 0.5000 - val_recall: 0.2000\n",
      "Epoch 64/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2058 - precision: 0.7172 - recall: 0.2394 - val_loss: 0.3388 - val_precision: 0.5625 - val_recall: 0.1929\n",
      "Epoch 65/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2057 - precision: 0.7234 - recall: 0.2326 - val_loss: 0.3438 - val_precision: 0.5333 - val_recall: 0.1714\n",
      "Epoch 66/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2050 - precision: 0.7080 - recall: 0.2421 - val_loss: 0.3453 - val_precision: 0.5208 - val_recall: 0.1786\n",
      "Epoch 67/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2050 - precision: 0.6835 - recall: 0.2216 - val_loss: 0.3389 - val_precision: 0.5192 - val_recall: 0.1929\n",
      "Epoch 68/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2039 - precision: 0.7106 - recall: 0.2285 - val_loss: 0.3368 - val_precision: 0.5333 - val_recall: 0.1714\n",
      "Epoch 69/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2032 - precision: 0.6951 - recall: 0.2339 - val_loss: 0.3328 - val_precision: 0.5283 - val_recall: 0.2000\n",
      "Epoch 70/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2023 - precision: 0.7166 - recall: 0.2421 - val_loss: 0.3487 - val_precision: 0.5111 - val_recall: 0.1643\n",
      "Epoch 71/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.2029 - precision: 0.7184 - recall: 0.2408 - val_loss: 0.3403 - val_precision: 0.5200 - val_recall: 0.1857\n",
      "Epoch 72/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2020 - precision: 0.7160 - recall: 0.2449 - val_loss: 0.3439 - val_precision: 0.5217 - val_recall: 0.1714\n",
      "Epoch 73/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2011 - precision: 0.7176 - recall: 0.2503 - val_loss: 0.3429 - val_precision: 0.5208 - val_recall: 0.1786\n",
      "Epoch 74/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2008 - precision: 0.6914 - recall: 0.2298 - val_loss: 0.3376 - val_precision: 0.5357 - val_recall: 0.2143\n",
      "Epoch 75/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2010 - precision: 0.6935 - recall: 0.2476 - val_loss: 0.3524 - val_precision: 0.5088 - val_recall: 0.2071\n",
      "Epoch 76/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.2007 - precision: 0.7111 - recall: 0.2627 - val_loss: 0.3460 - val_precision: 0.5370 - val_recall: 0.2071\n",
      "Epoch 77/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1990 - precision: 0.6996 - recall: 0.2517 - val_loss: 0.3464 - val_precision: 0.5510 - val_recall: 0.1929\n",
      "Epoch 78/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1990 - precision: 0.7451 - recall: 0.2599 - val_loss: 0.3447 - val_precision: 0.5370 - val_recall: 0.2071\n",
      "Epoch 79/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1982 - precision: 0.7122 - recall: 0.2709 - val_loss: 0.3544 - val_precision: 0.5273 - val_recall: 0.2071\n",
      "Epoch 80/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1976 - precision: 0.6917 - recall: 0.2517 - val_loss: 0.3460 - val_precision: 0.5000 - val_recall: 0.2143\n",
      "Epoch 81/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1975 - precision: 0.7168 - recall: 0.2736 - val_loss: 0.3414 - val_precision: 0.5400 - val_recall: 0.1929\n",
      "Epoch 82/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1972 - precision: 0.7292 - recall: 0.2763 - val_loss: 0.3406 - val_precision: 0.5490 - val_recall: 0.2000\n",
      "Epoch 83/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1963 - precision: 0.7168 - recall: 0.2736 - val_loss: 0.3458 - val_precision: 0.5385 - val_recall: 0.2000\n",
      "Epoch 84/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1964 - precision: 0.6982 - recall: 0.2627 - val_loss: 0.3402 - val_precision: 0.5094 - val_recall: 0.1929\n",
      "Epoch 85/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1958 - precision: 0.7153 - recall: 0.2681 - val_loss: 0.3475 - val_precision: 0.5000 - val_recall: 0.1929\n",
      "Epoch 86/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1953 - precision: 0.7331 - recall: 0.2818 - val_loss: 0.3396 - val_precision: 0.5000 - val_recall: 0.1857\n",
      "Epoch 87/150\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.1948 - precision: 0.6996 - recall: 0.2709 - val_loss: 0.3485 - val_precision: 0.5294 - val_recall: 0.1929\n",
      "Epoch 88/150\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.1940 - precision: 0.7079 - recall: 0.2818 - val_loss: 0.3496 - val_precision: 0.5385 - val_recall: 0.2000\n",
      "Epoch 89/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1938 - precision: 0.7034 - recall: 0.2791 - val_loss: 0.3455 - val_precision: 0.5000 - val_recall: 0.2000\n",
      "Epoch 90/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1938 - precision: 0.7182 - recall: 0.2859 - val_loss: 0.3434 - val_precision: 0.5167 - val_recall: 0.2214\n",
      "Epoch 91/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1928 - precision: 0.6962 - recall: 0.2791 - val_loss: 0.3481 - val_precision: 0.4839 - val_recall: 0.2143\n",
      "Epoch 92/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1920 - precision: 0.7252 - recall: 0.2996 - val_loss: 0.3607 - val_precision: 0.5400 - val_recall: 0.1929\n",
      "Epoch 93/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1905 - precision: 0.7234 - recall: 0.2791 - val_loss: 0.3379 - val_precision: 0.4737 - val_recall: 0.2571\n",
      "Epoch 94/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1918 - precision: 0.7007 - recall: 0.2914 - val_loss: 0.3528 - val_precision: 0.4915 - val_recall: 0.2071\n",
      "Epoch 95/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1916 - precision: 0.7047 - recall: 0.2873 - val_loss: 0.3504 - val_precision: 0.4762 - val_recall: 0.2143\n",
      "Epoch 96/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1910 - precision: 0.7157 - recall: 0.2996 - val_loss: 0.3619 - val_precision: 0.5088 - val_recall: 0.2071\n",
      "Epoch 97/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1901 - precision: 0.7188 - recall: 0.3078 - val_loss: 0.3525 - val_precision: 0.5192 - val_recall: 0.1929\n",
      "Epoch 98/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1897 - precision: 0.7170 - recall: 0.3051 - val_loss: 0.3589 - val_precision: 0.4918 - val_recall: 0.2143\n",
      "Epoch 99/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1890 - precision: 0.7424 - recall: 0.2996 - val_loss: 0.3519 - val_precision: 0.4828 - val_recall: 0.2000\n",
      "Epoch 100/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1888 - precision: 0.7294 - recall: 0.3023 - val_loss: 0.3643 - val_precision: 0.4754 - val_recall: 0.2071\n",
      "Epoch 101/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1888 - precision: 0.7201 - recall: 0.3133 - val_loss: 0.3549 - val_precision: 0.4677 - val_recall: 0.2071\n",
      "Epoch 102/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1879 - precision: 0.7443 - recall: 0.3146 - val_loss: 0.3545 - val_precision: 0.4571 - val_recall: 0.2286\n",
      "Epoch 103/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1879 - precision: 0.7241 - recall: 0.3160 - val_loss: 0.3541 - val_precision: 0.4688 - val_recall: 0.2143\n",
      "Epoch 104/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1867 - precision: 0.7445 - recall: 0.3269 - val_loss: 0.3628 - val_precision: 0.4571 - val_recall: 0.2286\n",
      "Epoch 105/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1873 - precision: 0.7310 - recall: 0.3160 - val_loss: 0.3647 - val_precision: 0.4615 - val_recall: 0.2143\n",
      "Epoch 106/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1862 - precision: 0.7365 - recall: 0.3174 - val_loss: 0.3615 - val_precision: 0.4627 - val_recall: 0.2214\n",
      "Epoch 107/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1862 - precision: 0.7256 - recall: 0.3256 - val_loss: 0.3629 - val_precision: 0.4627 - val_recall: 0.2214\n",
      "Epoch 108/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1853 - precision: 0.7190 - recall: 0.3256 - val_loss: 0.3679 - val_precision: 0.4762 - val_recall: 0.2143\n",
      "Epoch 109/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1858 - precision: 0.7210 - recall: 0.3146 - val_loss: 0.3613 - val_precision: 0.4648 - val_recall: 0.2357\n",
      "Epoch 110/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1847 - precision: 0.7234 - recall: 0.3256 - val_loss: 0.3717 - val_precision: 0.4918 - val_recall: 0.2143\n",
      "Epoch 111/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1849 - precision: 0.7284 - recall: 0.3338 - val_loss: 0.3804 - val_precision: 0.4590 - val_recall: 0.2000\n",
      "Epoch 112/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1853 - precision: 0.7302 - recall: 0.3146 - val_loss: 0.3702 - val_precision: 0.4848 - val_recall: 0.2286\n",
      "Epoch 113/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1833 - precision: 0.7380 - recall: 0.3352 - val_loss: 0.3734 - val_precision: 0.4507 - val_recall: 0.2286\n",
      "Epoch 114/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1830 - precision: 0.7259 - recall: 0.3406 - val_loss: 0.3627 - val_precision: 0.4746 - val_recall: 0.2000\n",
      "Epoch 115/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1837 - precision: 0.7130 - recall: 0.3228 - val_loss: 0.3685 - val_precision: 0.4844 - val_recall: 0.2214\n",
      "Epoch 116/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1827 - precision: 0.7335 - recall: 0.3352 - val_loss: 0.3756 - val_precision: 0.4429 - val_recall: 0.2214\n",
      "Epoch 117/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1822 - precision: 0.7337 - recall: 0.3393 - val_loss: 0.3583 - val_precision: 0.4512 - val_recall: 0.2643\n",
      "Epoch 118/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1811 - precision: 0.7293 - recall: 0.3502 - val_loss: 0.3940 - val_precision: 0.4677 - val_recall: 0.2071\n",
      "Epoch 119/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1813 - precision: 0.7316 - recall: 0.3393 - val_loss: 0.3793 - val_precision: 0.4531 - val_recall: 0.2071\n",
      "Epoch 120/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1812 - precision: 0.7346 - recall: 0.3598 - val_loss: 0.3726 - val_precision: 0.4638 - val_recall: 0.2286\n",
      "Epoch 121/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1805 - precision: 0.7262 - recall: 0.3338 - val_loss: 0.3848 - val_precision: 0.4478 - val_recall: 0.2143\n",
      "Epoch 122/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1810 - precision: 0.7172 - recall: 0.3365 - val_loss: 0.3830 - val_precision: 0.4615 - val_recall: 0.2143\n",
      "Epoch 123/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1802 - precision: 0.7303 - recall: 0.3557 - val_loss: 0.3819 - val_precision: 0.4545 - val_recall: 0.2143\n",
      "Epoch 124/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1792 - precision: 0.7291 - recall: 0.3461 - val_loss: 0.3764 - val_precision: 0.4177 - val_recall: 0.2357\n",
      "Epoch 125/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1793 - precision: 0.7191 - recall: 0.3502 - val_loss: 0.3965 - val_precision: 0.4531 - val_recall: 0.2071\n",
      "Epoch 126/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1792 - precision: 0.7233 - recall: 0.3434 - val_loss: 0.3865 - val_precision: 0.4250 - val_recall: 0.2429\n",
      "Epoch 127/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1792 - precision: 0.7273 - recall: 0.3611 - val_loss: 0.3955 - val_precision: 0.4412 - val_recall: 0.2143\n",
      "Epoch 128/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1785 - precision: 0.7286 - recall: 0.3379 - val_loss: 0.3822 - val_precision: 0.4286 - val_recall: 0.2357\n",
      "Epoch 129/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1778 - precision: 0.7135 - recall: 0.3543 - val_loss: 0.3896 - val_precision: 0.4085 - val_recall: 0.2071\n",
      "Epoch 130/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1769 - precision: 0.7354 - recall: 0.3611 - val_loss: 0.4030 - val_precision: 0.4516 - val_recall: 0.2000\n",
      "Epoch 131/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1771 - precision: 0.7295 - recall: 0.3653 - val_loss: 0.3947 - val_precision: 0.4247 - val_recall: 0.2214\n",
      "Epoch 132/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1767 - precision: 0.7364 - recall: 0.3707 - val_loss: 0.3954 - val_precision: 0.4247 - val_recall: 0.2214\n",
      "Epoch 133/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1769 - precision: 0.7250 - recall: 0.3570 - val_loss: 0.4000 - val_precision: 0.4286 - val_recall: 0.2143\n",
      "Epoch 134/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1772 - precision: 0.7342 - recall: 0.3666 - val_loss: 0.3972 - val_precision: 0.4265 - val_recall: 0.2071\n",
      "Epoch 135/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1758 - precision: 0.7403 - recall: 0.3666 - val_loss: 0.3970 - val_precision: 0.4400 - val_recall: 0.2357\n",
      "Epoch 136/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1753 - precision: 0.7227 - recall: 0.3707 - val_loss: 0.4045 - val_precision: 0.4559 - val_recall: 0.2214\n",
      "Epoch 137/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1753 - precision: 0.7204 - recall: 0.3666 - val_loss: 0.3943 - val_precision: 0.4189 - val_recall: 0.2214\n",
      "Epoch 138/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1747 - precision: 0.7426 - recall: 0.3789 - val_loss: 0.3992 - val_precision: 0.4225 - val_recall: 0.2143\n",
      "Epoch 139/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1741 - precision: 0.7344 - recall: 0.3707 - val_loss: 0.3966 - val_precision: 0.3721 - val_recall: 0.2286\n",
      "Epoch 140/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1731 - precision: 0.7401 - recall: 0.3817 - val_loss: 0.4042 - val_precision: 0.4400 - val_recall: 0.2357\n",
      "Epoch 141/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1742 - precision: 0.7440 - recall: 0.3817 - val_loss: 0.4074 - val_precision: 0.4156 - val_recall: 0.2286\n",
      "Epoch 142/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1737 - precision: 0.7345 - recall: 0.3899 - val_loss: 0.4201 - val_precision: 0.4265 - val_recall: 0.2071\n",
      "Epoch 143/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1736 - precision: 0.7246 - recall: 0.3707 - val_loss: 0.4143 - val_precision: 0.3953 - val_recall: 0.2429\n",
      "Epoch 144/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1730 - precision: 0.7203 - recall: 0.3735 - val_loss: 0.4138 - val_precision: 0.4189 - val_recall: 0.2214\n",
      "Epoch 145/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1723 - precision: 0.7527 - recall: 0.3830 - val_loss: 0.4121 - val_precision: 0.4074 - val_recall: 0.2357\n",
      "Epoch 146/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1723 - precision: 0.7323 - recall: 0.3817 - val_loss: 0.4226 - val_precision: 0.4085 - val_recall: 0.2071\n",
      "Epoch 147/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1719 - precision: 0.7394 - recall: 0.3803 - val_loss: 0.4076 - val_precision: 0.3908 - val_recall: 0.2429\n",
      "Epoch 148/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1715 - precision: 0.7404 - recall: 0.3940 - val_loss: 0.4197 - val_precision: 0.4026 - val_recall: 0.2214\n",
      "Epoch 149/150\n",
      "133/133 [==============================] - 0s 3ms/step - loss: 0.1703 - precision: 0.7366 - recall: 0.3940 - val_loss: 0.4215 - val_precision: 0.4028 - val_recall: 0.2071\n",
      "Epoch 150/150\n",
      "133/133 [==============================] - 0s 2ms/step - loss: 0.1704 - precision: 0.7474 - recall: 0.3885 - val_loss: 0.4176 - val_precision: 0.3974 - val_recall: 0.2214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x148764d50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train it\n",
    "# unfortunately the model overfits like crazy and I don't know why... \n",
    "verbose, epochs, batch_size = 1, 150, 64\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard('./logs', update_freq=1)\n",
    "lstm_model.fit(time_series_training_data_shuffled, time_series_training_targets_shuffled, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data=(time_series_val_data, time_series_val_targets), callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.39743590354919434\n",
      "recall: 0.22142857313156128\n"
     ]
    }
   ],
   "source": [
    "result = lstm_model.evaluate(time_series_val_data, time_series_val_targets, batch_size=batch_size, verbose=0)\n",
    "print(f\"precision: {result[1]}\")\n",
    "print(f\"recall: {result[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.23595505952835083\n",
      "recall: 0.16153846681118011\n"
     ]
    }
   ],
   "source": [
    "result = lstm_model.evaluate(time_series_test_data, time_series_test_targets, batch_size=batch_size, verbose=0)\n",
    "print(f\"precision: {result[1]}\")\n",
    "print(f\"recall: {result[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-02-04'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts if it snows given the lstm model for the tomorrow 12 years ago  \n",
    "def tt_prediction(model, data, day_to_predict, time_stamp_amount):\n",
    "    OKGREEN = '\\033[92m'\n",
    "    FAIL = '\\033[91m'\n",
    "    \n",
    "    test_targets = []\n",
    "    test_samples = []\n",
    "    \n",
    "    day_to_predict_data = data[data['date'] == day_to_predict]\n",
    "    \n",
    "    stations = day_to_predict_data['station_number'].unique()\n",
    "    for station in stations:\n",
    "        station_data = data[data['station_number'] == station]\n",
    "        \n",
    "        predecessors_df = station_data[station_data['date'] < day_to_predict].tail(time_stamp_amount)\n",
    "        \n",
    "        feature_matrix = df_to_feature_matrix(predecessors_df)\n",
    "        target = day_to_predict_data['snow'].to_numpy()\n",
    "        \n",
    "        test_samples.append(feature_matrix)\n",
    "        test_targets.append(target)\n",
    "        \n",
    "    test_samples = np.stack(test_samples)\n",
    "    test_targets = np.stack(test_targets)\n",
    "    \n",
    "    prediction = lstm_model.predict(test_samples)\n",
    "    \n",
    "    for index, station in enumerate(stations):\n",
    "        predicted_class = np.round(prediction[index][0])\n",
    "        if predicted_class == target[index]:   \n",
    "            print(f\"{OKGREEN}Prediction for station {station}: correct - predicted:{predicted_class} == target:{target[index]} {OKGREEN}\")\n",
    "        else:\n",
    "            print(f\"{FAIL}Prediction for station {station}: incorrect - : prediction:{predicted_class} != target:{target[index]} {FAIL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mPrediction for station 725326: correct - predicted:0.0 == target:0 \u001b[92m\n",
      "\u001b[91mPrediction for station 725317: incorrect - : prediction:1.0 != target:0 \u001b[91m\n",
      "\u001b[92mPrediction for station 725300: correct - predicted:0.0 == target:0 \u001b[92m\n",
      "\u001b[92mPrediction for station 725327: correct - predicted:0.0 == target:0 \u001b[92m\n",
      "\u001b[92mPrediction for station 725305: correct - predicted:0.0 == target:0 \u001b[92m\n",
      "\u001b[92mPrediction for station 725314: correct - predicted:0.0 == target:0 \u001b[92m\n",
      "\u001b[92mPrediction for station 725330: correct - predicted:0.0 == target:0 \u001b[92m\n",
      "\u001b[92mPrediction for station 725320: correct - predicted:0.0 == target:0 \u001b[92m\n",
      "\u001b[92mPrediction for station 725316: correct - predicted:0.0 == target:0 \u001b[92m\n",
      "\u001b[92mPrediction for station 725315: correct - predicted:0.0 == target:0 \u001b[92m\n"
     ]
    }
   ],
   "source": [
    "tt_prediction(lstm_model, features_df, day_to_predict, time_stamp_amount)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
